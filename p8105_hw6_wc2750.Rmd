---
title: "p8105_hw6_wc2750"
author: "Weixi Chen"
date: "12/8/2020"
output: github_document
---
```{r setup, include = F}
library(tidyverse)
library(modelr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5)))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1
```{r message = F, warning = F}
homicide_df = 
  read_csv("data/homicide-data.csv") %>%
  mutate(
    city_state = str_c(city, state, sep = ", "),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1
    ),
    victim_age = as.numeric(victim_age)
  ) %>%
  filter(victim_race %in% c("White", "Black"),
         city_state != "Tulsa, AL") %>%
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

Start with one city
```{r}
baltimore_df =
  homicide_df %>%
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_race + victim_sex, data = baltimore_df,
    family = binomial()) %>%
  broom::tidy() %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  select(term, OR, starts_with("CI")) %>%
  knitr::kable(digits = 3)
```

Try this across cities
```{r}
models_results_df = 
  homicide_df %>%
  nest(data = -city_state) %>%
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())),
    results = map(models, broom::tidy)
  ) %>%
  select(city_state, results) %>%
  unnest(results) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  select(city_state, term, OR, starts_with("CI"))
```

```{r}
models_results_df %>%
  filter(term == "victim_sexMale") %>%
  mutate(city_state = fct_reorder(city_state, OR)) %>%
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  labs(x = "City, State" , title = "OR by region with 95% confidence level") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

## Problem 2
Load and clean child's birthweight data
```{r message = F}
baby_df = 
  read_csv("data/birthweight.csv") %>%
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace)) %>%
  mutate(mrace = case_when(mrace == 1 ~ "White",
                           mrace == 2 ~ "Black",
                           mrace == 3 ~ "Asian",
                           mrace == 4 ~ "Puerto Rican",
                           mrace == 8 ~ "Other"),
         babysex = case_when(babysex == 1 ~ "male",
                             babysex == 2 ~ "female"),
         frace = case_when(frace == 1 ~ "White",
                           frace == 2 ~ "Black",
                           frace == 3 ~ "Asian",
                           frace == 4 ~ "Puerto Rican",
                           frace == 8 ~ "Other",
                           frace == 9 ~ "Unknown"),
         malform = case_when(malform == 0 ~ "absent",
                             malform == 1 ~ "present")
         ) %>%
  drop_na()
```

Propose a regression model for birthweight through stepwise
```{r results = "hide"}
reg_all = lm(bwt ~ ., data = baby_df)
step(reg_all, direction='both')

reg_step = lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data = baby_df)

reg_step %>%
  broom::tidy() %>% 
  select(term, estimate, p.value) %>%
  knitr::kable(digits = 3)
```

```{r}
reg_1 = lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mheight + parity + ppwt + smoken, data = baby_df)

summary(reg_1)
```
My hypothesized model, based on stepwise modeling selection and significant p-values smaller than 0.05, includes predictors: babysex, bhead, blength, delwt, gaweeks, mheight, parity, ppwt, and smoken. The adjusted R-squared is 0.70, indicating that a high persentage of variations in the birthweight can be explained by these predictors.

Plot of model residuals against fitted values
```{r}
baby_df %>%
  add_residuals(reg_1) %>%
  add_predictions(reg_1) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  labs(x = "Predictions", y = "Residuals", title = "Residuals vs Predictions")
```

Based on this model diagnosis plot, we can see that majority of predictions are centered around residuals 0, though there is few outliers with low prediction and high residual, scattering on the upper-left corner of the plot.

Compare my model to two others through cross-validation:\
* One using length at birth and gestational age as predictors (main effects only)\
* One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
```{r}
reg_2 = lm(bwt ~ blength + gaweeks, data = baby_df)

reg_2 %>%
  broom::tidy() %>% 
  select(term, estimate, p.value) %>%
  knitr::kable(digits = 3)

reg_3 = lm(bwt ~ bhead * blength * babysex, data = baby_df)

reg_3 %>%
  broom::tidy() %>% 
  select(term, estimate, p.value) %>%
  knitr::kable(digits = 3)
```

```{r warning = F}
set.seed(1)
cv_df = 
  crossv_mc(baby_df, 100) %>% 
   mutate(
        train = map(train, as_tibble),
        test = map(test, as_tibble)
    )

cv_df = 
  cv_df %>% 
  mutate(
    model_1  = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mheight + parity + ppwt + smoken, data = .x)),
    model_2  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_3  = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = .x))) %>% 
  mutate(
    rmse_1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
    rmse_2 = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)),
    rmse_3 = map2_dbl(model_3, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()

```

Based on the cross-validation by comparing rmse value, my proposed model has the lowest rmse, indictaing it is best model among these three models. Model 3 is also a good choice since it has relatively smaller number of predictors and also a small rmse.
